{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51637940",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b390af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"product_names.csv\")\n",
    "df.head(5)\n",
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c963ef31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Includes Special Offers, Magenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kindle Oasis E-reader with Leather Charging Cover - Merlot, 6 High-Resolution Display (300 ppi), Wi-Fi - Includes Special Offers,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Kindle Lighted Leather Cover,,,\\r\\nAmazon Kindle Lighted Leather Cover,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Kindle Lighted Leather Cover,,,\\r\\nKindle Keyboard,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kindle Keyboard,,,\\r\\nKindle Keyboard,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 32 GB - Includes Special Offers, Magenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fire HD 8 Tablet with Alexa, 8 HD Display, 32 GB, Tangerine - with Special Offers,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders,,,\\r\\nAmazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>All-New Kindle E-reader - Black, 6 Glare-Free Touchscreen Display, Wi-Fi -  Includes Special Offers,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amazon Kindle Fire Hd (3rd Generation) 8gb,,,\\r\\nAmazon Kindle Fire Hd (3rd Generation) 8gb,,,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                   Product Name\n",
       "0                                                                                                       All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Includes Special Offers, Magenta\n",
       "1                                                            Kindle Oasis E-reader with Leather Charging Cover - Merlot, 6 High-Resolution Display (300 ppi), Wi-Fi - Includes Special Offers,,\n",
       "2                                                                                                              Amazon Kindle Lighted Leather Cover,,,\\r\\nAmazon Kindle Lighted Leather Cover,,,\n",
       "3                                                                                                                                  Amazon Kindle Lighted Leather Cover,,,\\r\\nKindle Keyboard,,,\n",
       "4                                                                                                                                                      Kindle Keyboard,,,\\r\\nKindle Keyboard,,,\n",
       "5                                                                                                       All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 32 GB - Includes Special Offers, Magenta\n",
       "6                                                                                                            Fire HD 8 Tablet with Alexa, 8 HD Display, 32 GB, Tangerine - with Special Offers,\n",
       "7  Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders,,,\\r\\nAmazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders,,,\n",
       "8                                                                                         All-New Kindle E-reader - Black, 6 Glare-Free Touchscreen Display, Wi-Fi -  Includes Special Offers,,\n",
       "9                                                                                                Amazon Kindle Fire Hd (3rd Generation) 8gb,,,\\r\\nAmazon Kindle Fire Hd (3rd Generation) 8gb,,,"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18dc6770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Product Name'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dfc0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df['Product Name'].str.replace(\"\\r\\n\", \"\").str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c777b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty_removed = df_cleaned.apply(lambda row: list(filter (None, row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7f91bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                             [All-New Fire HD 8 Tablet,  8 HD Display,  Wi-Fi,  16 GB - Includes Special Offers,  Magenta]\n",
       "1                                                      [Kindle Oasis E-reader with Leather Charging Cover - Merlot,  6 High-Resolution Display (300 ppi),  Wi-Fi - Includes Special Offers]\n",
       "2                                                                                                                [Amazon Kindle Lighted Leather Cover, Amazon Kindle Lighted Leather Cover]\n",
       "3                                                                                                                                    [Amazon Kindle Lighted Leather Cover, Kindle Keyboard]\n",
       "4                                                                                                                                                        [Kindle Keyboard, Kindle Keyboard]\n",
       "5                                                                                             [All-New Fire HD 8 Tablet,  8 HD Display,  Wi-Fi,  32 GB - Includes Special Offers,  Magenta]\n",
       "6                                                                                                    [Fire HD 8 Tablet with Alexa,  8 HD Display,  32 GB,  Tangerine - with Special Offers]\n",
       "7    [Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders, Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders]\n",
       "8                                                                                   [All-New Kindle E-reader - Black,  6 Glare-Free Touchscreen Display,  Wi-Fi -  Includes Special Offers]\n",
       "9                                                                                                  [Amazon Kindle Fire Hd (3rd Generation) 8gb, Amazon Kindle Fire Hd (3rd Generation) 8gb]\n",
       "Name: Product Name, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_empty_removed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec17680",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_product_names = df_empty_removed.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b7fbd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_product_description = df_empty_removed.apply(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bbf86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_name = pd.DataFrame({'Product Name':all_product_names, 'Description':all_product_description})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16ea58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_name['Description'] = df_product_name['Description'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cff43ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-New Fire HD 8 Tablet</td>\n",
       "      <td>8 HD Display  Wi-Fi  16 GB - Includes Special Offers  Magenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kindle Oasis E-reader with Leather Charging Cover - Merlot</td>\n",
       "      <td>6 High-Resolution Display (300 ppi)  Wi-Fi - Includes Special Offers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Kindle Lighted Leather Cover</td>\n",
       "      <td>Amazon Kindle Lighted Leather Cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Kindle Lighted Leather Cover</td>\n",
       "      <td>Kindle Keyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kindle Keyboard</td>\n",
       "      <td>Kindle Keyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>All-New Fire HD 8 Tablet</td>\n",
       "      <td>8 HD Display  Wi-Fi  32 GB - Includes Special Offers  Magenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fire HD 8 Tablet with Alexa</td>\n",
       "      <td>8 HD Display  32 GB  Tangerine - with Special Offers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders</td>\n",
       "      <td>Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>All-New Kindle E-reader - Black</td>\n",
       "      <td>6 Glare-Free Touchscreen Display  Wi-Fi -  Includes Special Offers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amazon Kindle Fire Hd (3rd Generation) 8gb</td>\n",
       "      <td>Amazon Kindle Fire Hd (3rd Generation) 8gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                Product Name  \\\n",
       "0                                                                   All-New Fire HD 8 Tablet   \n",
       "1                                 Kindle Oasis E-reader with Leather Charging Cover - Merlot   \n",
       "2                                                        Amazon Kindle Lighted Leather Cover   \n",
       "3                                                        Amazon Kindle Lighted Leather Cover   \n",
       "4                                                                            Kindle Keyboard   \n",
       "5                                                                   All-New Fire HD 8 Tablet   \n",
       "6                                                                Fire HD 8 Tablet with Alexa   \n",
       "7  Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders   \n",
       "8                                                            All-New Kindle E-reader - Black   \n",
       "9                                                 Amazon Kindle Fire Hd (3rd Generation) 8gb   \n",
       "\n",
       "                                                                                 Description  \n",
       "0                              8 HD Display  Wi-Fi  16 GB - Includes Special Offers  Magenta  \n",
       "1                       6 High-Resolution Display (300 ppi)  Wi-Fi - Includes Special Offers  \n",
       "2                                                        Amazon Kindle Lighted Leather Cover  \n",
       "3                                                                            Kindle Keyboard  \n",
       "4                                                                            Kindle Keyboard  \n",
       "5                              8 HD Display  Wi-Fi  32 GB - Includes Special Offers  Magenta  \n",
       "6                                       8 HD Display  32 GB  Tangerine - with Special Offers  \n",
       "7  Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders  \n",
       "8                         6 Glare-Free Touchscreen Display  Wi-Fi -  Includes Special Offers  \n",
       "9                                                 Amazon Kindle Fire Hd (3rd Generation) 8gb  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_name.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "939cb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_name_unique = df_product_name.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f64c732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dikshashukla\\AppData\\Local\\Temp\\ipykernel_28748\\221742320.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_product_name_unique.loc['Product Name'] = df_product_name_unique['Product Name'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "df_product_name_unique.loc['Product Name'] = df_product_name_unique['Product Name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aa9dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dikshashukla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "def remove_stop_words (line):\n",
    "    tokens = word_tokenize(line)\n",
    "    new_filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return \" \".join(new_filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c284065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sample = df_product_name_unique.sample(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48864424",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sample['Product Name'] = product_sample['Product Name'].apply(lambda x: remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "312d7c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>854152</th>\n",
       "      <td>mss sesame street birthday party supplies bundle pack 16 guests</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503671</th>\n",
       "      <td>collomix kr120hf steel hexafix quick connect grout/joint compound stirring paddel</td>\n",
       "      <td>4.72\" Diameter x 23.23\" Length  For 5 Gallons Mixers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242967</th>\n",
       "      <td>ore international 6129bk 32-inch metal lamp</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632844</th>\n",
       "      <td>3drose lsp_30652_2 bold orange double toggle switch</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247093</th>\n",
       "      <td>crz yoga women 's brushed naked feeling ii high waisted yoga pants tummy control workout leggings -25 inches</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236973</th>\n",
       "      <td>sterling silver open teardrop filigree dangle earrings</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642720</th>\n",
       "      <td>usb charger wall outlet dual high speed duplex receptacle 15 amp</td>\n",
       "      <td>Smart 4.8A Quick Charging Capability  Tamper Resistant Outlet Wall plate Included UL Listed White MICMI C48 (4.8A USB outlet 2pack)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369593</th>\n",
       "      <td>magma marine kettle 3 combination stove &amp; gas grill</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324094</th>\n",
       "      <td>tempt women retro 80 's fashion swimsuit high cut low back one piece swimwear</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944259</th>\n",
       "      <td>steampunkers usa big heart collection - 30mm double turquoise blue - 20-22 inch black cord – crystal gemstone carved necklace charm handmade</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         Product Name  \\\n",
       "854152                                                                                mss sesame street birthday party supplies bundle pack 16 guests   \n",
       "503671                                                              collomix kr120hf steel hexafix quick connect grout/joint compound stirring paddel   \n",
       "2242967                                                                                                   ore international 6129bk 32-inch metal lamp   \n",
       "632844                                                                                            3drose lsp_30652_2 bold orange double toggle switch   \n",
       "247093                                   crz yoga women 's brushed naked feeling ii high waisted yoga pants tummy control workout leggings -25 inches   \n",
       "1236973                                                                                        sterling silver open teardrop filigree dangle earrings   \n",
       "642720                                                                               usb charger wall outlet dual high speed duplex receptacle 15 amp   \n",
       "2369593                                                                                           magma marine kettle 3 combination stove & gas grill   \n",
       "324094                                                                  tempt women retro 80 's fashion swimsuit high cut low back one piece swimwear   \n",
       "1944259  steampunkers usa big heart collection - 30mm double turquoise blue - 20-22 inch black cord – crystal gemstone carved necklace charm handmade   \n",
       "\n",
       "                                                                                                                                  Description  \n",
       "854152                                                                                                                                         \n",
       "503671                                                                                   4.72\" Diameter x 23.23\" Length  For 5 Gallons Mixers  \n",
       "2242967                                                                                                                                 Black  \n",
       "632844                                                                                                                                         \n",
       "247093                                                                                                                                         \n",
       "1236973                                                                                                                                        \n",
       "642720    Smart 4.8A Quick Charging Capability  Tamper Resistant Outlet Wall plate Included UL Listed White MICMI C48 (4.8A USB outlet 2pack)  \n",
       "2369593                                                                                                                                        \n",
       "324094                                                                                                                                         \n",
       "1944259                                                                                                                                        "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d5e7c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cbfbba0c7444a4a490453c0e5fd299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f8e2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(product_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2434830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"buckle-down junior 's canvas coin purse deadpool\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Product Name\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3095197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"gpt2\"\n",
    "tokenizer_checkpoint = \"sgugger/gpt2-like-tokenizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f94909b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9eb07c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(tokenizer, dataset_name):\n",
    "    return tokenizer(dataset_name[\"Product Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72573aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "partial_tokenize_function = partial(tokenize_function, tokenizer)\n",
    "tokenized_datasets = dataset.map(partial_tokenize_function, batched=True, num_proc=4, remove_columns=[\"Product Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3f5134c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Description', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 15000\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "118e1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    print (examples)\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0ac831c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717a639582574ab3aa35c888629d4a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\dikshashukla\\AppData\\Local\\anaconda3\\Lib\\site-packages\\multiprocess\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dikshashukla\\AppData\\Local\\anaconda3\\Lib\\site-packages\\datasets\\utils\\py_utils.py\", line 1353, in _write_generator_to_queue\n    for i, result in enumerate(func(**kwargs)):\n  File \"C:\\Users\\dikshashukla\\AppData\\Local\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py\", line 3449, in _map_single\n    batch = apply_function_on_filtered_inputs(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dikshashukla\\AppData\\Local\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py\", line 3330, in apply_function_on_filtered_inputs\n    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dikshashukla\\AppData\\Local\\Temp\\ipykernel_28748\\2828127563.py\", line 4, in group_texts\n  File \"C:\\Users\\dikshashukla\\AppData\\Local\\Temp\\ipykernel_28748\\2828127563.py\", line 4, in <dictcomp>\nTypeError: can only concatenate list (not \"str\") to list\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lm_datasets \u001b[38;5;241m=\u001b[39m tokenized_datasets\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m      2\u001b[0m     group_texts,\n\u001b[0;32m      3\u001b[0m     batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m      5\u001b[0m     num_proc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:578\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    579\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:543\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    541\u001b[0m }\n\u001b[0;32m    542\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    544\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:3166\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3158\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3159\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[0;32m   3160\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   3161\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3164\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3165\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3166\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m iflatmap_unordered(\n\u001b[0;32m   3167\u001b[0m         pool, Dataset\u001b[38;5;241m.\u001b[39m_map_single, kwargs_iterable\u001b[38;5;241m=\u001b[39mkwargs_per_job\n\u001b[0;32m   3168\u001b[0m     ):\n\u001b[0;32m   3169\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3170\u001b[0m             shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\datasets\\utils\\py_utils.py:1379\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[1;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[0;32m   1376\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     [async_result\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\datasets\\utils\\py_utils.py:1379\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1376\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     [async_result\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\multiprocess\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a05eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 128\n",
    "        self.num_layers = 3\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc36bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "    ):\n",
    "        self.args = args\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        train_df = pd.read_csv('data/reddit-cleanjokes.csv')\n",
    "        text = train_df['Joke'].str.cat(sep=' ')\n",
    "        return text.split(' ')\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.args.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.args.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.args.sequence_length+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from model import Model\n",
    "from dataset import Dataset\n",
    "\n",
    "def train(dataset, model, args):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(args.max_epochs):\n",
    "        state_h, state_c = model.init_state(args.sequence_length)\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
    "\n",
    "def predict(dataset, model, text, next_words=100):\n",
    "    words = text.split(' ')\n",
    "    model.eval()\n",
    "\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return words\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--max-epochs', type=int, default=10)\n",
    "parser.add_argument('--batch-size', type=int, default=256)\n",
    "parser.add_argument('--sequence-length', type=int, default=4)\n",
    "args = parser.parse_args()\n",
    "\n",
    "dataset = Dataset(args)\n",
    "model = Model(dataset)\n",
    "\n",
    "train(dataset, model, args)\n",
    "print(predict(dataset, model, text='Knock knock. Whos there?'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
